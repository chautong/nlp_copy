{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "262aa132",
   "metadata": {},
   "source": [
    "# Embeddings \n",
    "\n",
    "After text has been preprocessed, the next step involves mapping this concise version of the text to numbers, namely vectors. These vector representations of words or phrases are called **embeddings**. There are endless ways to generate these vectors, but weâ€™ll only highlight frequently used techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba30653",
   "metadata": {},
   "source": [
    "## Counting Based Embedding Techniques \n",
    "\n",
    "For the most part, these methods for generating embeddings can be broken down into counting based approaches and more complex, neural network based approaches.Starting with the former, many of the counting based methods have been replaced by their neural network counterparts, but two of the somewhat still popular techniques are Term Frequency Inverse Document Frequency (TF-IDF)  and Bag of Words (BOW). Starting with TF-IDF, this method assigns a score to each word in a document based on its frequency and the frequency of the words in the corpus.Using the product of  term frequency and the inverse document frequency, TF-IDF measures the originality of a word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90db934",
   "metadata": {},
   "source": [
    "![tfidf](docs/images/tfidf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab563863",
   "metadata": {},
   "source": [
    "In order to generate the *TF-IDF* vector, we'll need to rely on the `sklearn` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b43fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"Hey! I'm new in town.\"\n",
    "          \"Can you please point me in the direction of the groccery store\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380954fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an instace of the TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True)\n",
    "\n",
    "# Fit the vectorizer to corputs \n",
    "fitted_vectorizer = vectorizer.fit(corpus)\n",
    "\n",
    "# Transform the corpuse using the fit vectorizer \n",
    "X = fitted_vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b319f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the feature names \n",
    "fitted_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5a6ab",
   "metadata": {},
   "source": [
    "Note that in the code above, the `fit` and `transform` calls for the vectorizer are broken down into two separate steps. Alternatively, the `fit_transform` method can combine these two steps into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix into a Pandas DataFrame for later modeling \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X[0].T.todense(), \n",
    "                  index = fitted_vectorizer.get_feature_names(), \n",
    "                  columns=[\"TF-IDF\"]\n",
    "                 )\n",
    "print(df.sort_values(\"TF-IDF\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb8a18",
   "metadata": {},
   "source": [
    "## Bag of Words\n",
    "\n",
    "Alternatively, BOW describes the occurrence of the words within a document. It counts the frequency of words, ignoring grammar and order, and creates vectors that reflect the importance of words via their frequency in the document. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b2571",
   "metadata": {},
   "source": [
    "![bow](docs/images/bow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e1c9f",
   "metadata": {},
   "source": [
    "Simliar to *TF-IDF*, we'll leverage `sklearn`'s `CountVectorizer` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858950f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Instantiate Count Vectorizer \n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit to the corpus \n",
    "fitted_vectorizer = vectorizer.fit(corpus)\n",
    "\n",
    "# Transform using fitted vectorizer \n",
    "X = fitted_vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix into a Pandas DataFrame for later modeling \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X[0].T.todense(), \n",
    "                  index = fitted_vectorizer.get_feature_names(), \n",
    "                  columns=[\"Bag of Words\"]\n",
    "                 )\n",
    "print(df.sort_values(\"Bag of Words\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
